{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def shape(tensor: Tensor) -> List[int]:\n",
    "    sizes: List[int] = []\n",
    "    while isinstance(tensor, list):\n",
    "        sizes.append(len(tensor))\n",
    "        tensor = tensor[0]\n",
    "    \n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "[1, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(shape([[23,4,5], [45,55]]))\n",
    "print(shape([[[12,4,5], [32,5,6], [4,56,24]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_1d(tensor: Tensor) -> bool:\n",
    "    '''\n",
    "    If tensor[0] is a list, its a higher-order tensor.\n",
    "    Otherwise, tensor is 1-dimensional (that is, a vector).'''\n",
    "    return not isinstance(tensor[0], list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(is_1d([1,3,4]))\n",
    "print(is_1d([[12,3], [325,5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_sum(tensor: Tensor) -> float:\n",
    "    '''sums up all the values in the tensor'''\n",
    "    if is_1d(tensor):\n",
    "        return sum(tensor)\n",
    "    else:\n",
    "        return sum(tensor_sum(tensor_i)\n",
    "                   for tensor_i in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(tensor_sum([[1,2,4], [1,3,4], [1,34,5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_apply(f: Callable[[float], float], tensor: Tensor) -> Tensor:\n",
    "    '''appliers f elementwise'''\n",
    "    if is_1d(tensor):\n",
    "        return [f(x) for x in tensor]\n",
    "    else:\n",
    "        return [tensor_apply(f, tensor_i) for tensor_i in tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "[[2, 4], [6, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor_apply(lambda x: x+1, [1,2,3]))\n",
    "\n",
    "print(tensor_apply(lambda x: 2*x, [[1,2], [3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros_like(tensor: Tensor) -> Tensor:\n",
    "    return tensor_apply(lambda _ : 0.0, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0]\n",
      "[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(zeros_like([1,2,4]))\n",
    "print(zeros_like([[12,4,5], [12,4,5], [35,5, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_combine(f: Callable[[float, float], float],\n",
    "                   t1: Tensor,\n",
    "                   t2: Tensor) -> Tensor:\n",
    "    '''applies f to corresponding elements of t1 and t2'''\n",
    "    if is_1d(t1):\n",
    "        return [f(x, y) for x, y in zip(t1, t2)]\n",
    "    else:\n",
    "        return [tensor_combine(f, t1_i, t2_i)\n",
    "                for t1_i, t2_i in zip(t1, t2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 9]\n",
      "\n",
      "[4, 10, 18]\n"
     ]
    }
   ],
   "source": [
    "print(tensor_combine(operator.add, [1,2,3], [4,5,6]));print()\n",
    "print(tensor_combine(operator.mul, [1,2,3], [4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Layer Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    '''our neural network will be composed of Layers, each of which knows how to do some \n",
    "    computation on its inputs in the \"forward\" direction and propagate gradients in the\n",
    "    \"backward\", direction'''\n",
    "    def forward(self, input):\n",
    "        '''Note the lack of types. \n",
    "        We re not going to be prescriptive about what kinds of inputs layers can take \n",
    "        and what kinds of ouputs they can return '''\n",
    "        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"\n",
    "        Similarly, we're not going to be prescriptive about what the\n",
    "        gradient looks like. It's up to you the user to make sure\n",
    "        that you're doing things sensibly.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        Returns the parameters of this layer. The default implementation\n",
    "        returns nothing, so that if you have a layer with no parameters\n",
    "        you don't have to implement this.\n",
    "        \"\"\"\n",
    "        return ()\n",
    "\n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        Returns the gradients, in the same order as params()\n",
    "        \"\"\"\n",
    "        return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        '''Apply Sigmoid to each element of the input tensor,\n",
    "        and save the result to use in backpropagration'''\n",
    "        self.sigmoids = tensor_apply(sigmoid, input)\n",
    "        return self.sigmoids\n",
    "    \n",
    "    def backwark(self, gradient: Tensor) -> Tensor:\n",
    "        return tensor_combine(lambda sig, grad: sig * (1 - sig) * grad, self.sigmoids, gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit ('data-science': pipenv)",
   "language": "python",
   "name": "python38532bitdatasciencepipenv068ffcbeb4194e50aa43c9cde15e24a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
